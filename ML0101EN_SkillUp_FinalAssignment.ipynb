{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b05306-4cc4-42a1-8e2e-900a0c2d1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 2)\n",
      "X_test shape: (20, 2)\n",
      "y_train shape: (80,)\n",
      "y_test shape: (20,)\n",
      "\n",
      "Training data preview:\n",
      "          X1         X2\n",
      "55  9.218742   4.841105\n",
      "88  8.872127  10.593012\n",
      "26  1.996738  16.360295\n",
      "42  0.343885   9.944970\n",
      "69  9.868869  11.817859\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate random data for regression\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "\n",
    "# Features: Generate two random independent variables\n",
    "X1 = np.random.rand(num_samples) * 10  # Random values between 0 and 10\n",
    "X2 = np.random.rand(num_samples) * 20  # Random values between 0 and 20\n",
    "\n",
    "# Target: Dependent variable with some noise\n",
    "y = 5 * X1 + 3 * X2 + np.random.randn(num_samples) * 2  # Linear relationship with noise\n",
    "\n",
    "# Combine into a DataFrame\n",
    "data = pd.DataFrame({'X1': X1, 'X2': X2, 'target': y})\n",
    "\n",
    "# Separate features and target\n",
    "X = data[['X1', 'X2']]  # Features\n",
    "y = data['target']      # Target\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Print a preview of the training data\n",
    "print(\"\\nTraining data preview:\")\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4965641-fda0-414a-b897-106068950d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Mean Squared Error (MSE): 2.67\n",
      "Mean Absolute Error (MAE): 1.47\n",
      "R-squared (R2): 1.00\n",
      "\n",
      "Model Coefficients:\n",
      "Intercept: -0.41\n",
      "Coefficients: [4.95000442 3.07871737]\n",
      "\n",
      "Comparison of Actual vs Predicted:\n",
      "       Actual  Predicted\n",
      "83  57.086117  56.754254\n",
      "53  72.232883  74.018243\n",
      "70  80.638621  79.533249\n",
      "45  35.646781  34.652687\n",
      "44  28.261714  29.935003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 1: Generate random data for regression\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "\n",
    "# Features: Generate two random independent variables\n",
    "X1 = np.random.rand(num_samples) * 10  # Random values between 0 and 10\n",
    "X2 = np.random.rand(num_samples) * 20  # Random values between 0 and 20\n",
    "\n",
    "# Target: Dependent variable with some noise\n",
    "y = 5 * X1 + 3 * X2 + np.random.randn(num_samples) * 2  # Linear relationship with noise\n",
    "\n",
    "# Combine into a DataFrame\n",
    "data = pd.DataFrame({'X1': X1, 'X2': X2, 'target': y})\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X = data[['X1', 'X2']]  # Features\n",
    "y = data['target']      # Target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Print evaluation metrics and model coefficients\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "print(f\"Coefficients: {model.coef_}\")  # Corresponds to [X1, X2]\n",
    "\n",
    "# Optional: Preview predictions vs actual values\n",
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(\"\\nComparison of Actual vs Predicted:\")\n",
    "print(comparison.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cc3ad-90fa-412f-b74b-0185f3e7d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define a function to create a regression report\n",
    "def create_regression_report(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        \"Metric\": [\"Mean Squared Error (MSE)\", \"Mean Absolute Error (MAE)\", \"R-squared (R2)\"],\n",
    "        \"Value\": [mse, mae, r2]\n",
    "    }\n",
    "    \n",
    "    # Convert to a DataFrame for tabular representation\n",
    "    report = pd.DataFrame(metrics)\n",
    "    return report\n",
    "\n",
    "# Step 2: Call the function to generate the report\n",
    "regression_report = create_regression_report(y_test, y_pred)\n",
    "\n",
    "# Display the report\n",
    "print(\"Final Regression Report:\")\n",
    "print(regression_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93999c4b-712d-4e8b-9dac-2f4a319fb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 1: Generate synthetic data\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the KNN model\n",
    "k = 5  # Number of neighbors\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Display the metrics\n",
    "print(\"Evaluation Metrics for KNN Regression:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c34f3-08b2-4a3c-b55e-b0ee88a91dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 1: Generate synthetic data\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the Decision Tree model\n",
    "tree_model = DecisionTreeRegressor(random_state=42, max_depth=5)  # Adjust max_depth for better performance\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Display the metrics\n",
    "print(\"Evaluation Metrics for Decision Tree Regression:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ea899-f3f6-465e-a089-ed0940d178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Generate synthetic classification data\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, random_state=42)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Display the metrics\n",
    "print(\"Evaluation Metrics for Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1aec6-b9d7-4803-95e4-242cf6b6392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Generate synthetic classification data\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, random_state=42)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Display the metrics\n",
    "print(\"Evaluation Metrics for SVM:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93603257-6913-4aea-900d-8dfafab363ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Generate synthetic classification data\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, random_state=42)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Step 5: Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Step 6: Display the report\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
